{
  "model_name_or_path": "roberta-base",
  "dataset_name": "wikitext",
  "dataset_config_name": "wikitext-103-v1",
  "do_train": true,
  "per_device_train_batch_size": 32,
  "max_steps": 1000000,
  "fp16": true,
  "weight_decay": 0.001,
  "adam_epsilon": 3e-6,
  "warmup_ratio": 0.01,
  "learning_rate": 1e-4,
  "do_eval": true,
  "evaluation_strategy": "steps",
  "eval_steps": 500,
  "per_device_eval_batch_size": 32,
  "output_dir": "./results",
  "overwrite_output_dir": true,
  "run_name": "mlm_bl"
}
